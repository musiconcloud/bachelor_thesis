{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as spdist\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "# for performance measurement\n",
    "# %lprun -f [function to profile] [execution trigger]\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6540000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_scores = np.fromfile(\"native-queries/native-query-scores.bin\", dtype='f')\n",
    "query_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.      0.86154 0.76303 0.70082 0.69154 0.63187 0.63078 0.597   0.39991\n",
      " 0.39806 0.34944 0.3238  0.31499 0.2983  0.24113 0.23587 0.233   0.22473\n",
      " 0.22309 0.21943 0.20288 0.19483 0.19241 0.18163 0.17281 0.17081 0.16959\n",
      " 0.16804 0.16621 0.16207 0.16194 0.15713 0.15247 0.14817 0.1462  0.14411\n",
      " 0.14166 0.13771 0.13493 0.13477 0.13264 0.13195 0.12906 0.12826 0.12664\n",
      " 0.12257 0.12221 0.12177 0.11971 0.11966 0.11786 0.11386 0.11345 0.11311\n",
      " 0.11298 0.1124  0.11113 0.10563 0.10419 0.10283 0.10262 0.10107 0.1008\n",
      " 0.10015 0.09225 0.09151 0.08893 0.08851 0.08758 0.08668 0.0863  0.08616\n",
      " 0.08545 0.08544 0.08505 0.08456 0.08343 0.08306 0.08281 0.08263 0.08257\n",
      " 0.08188 0.08015 0.07971 0.07845 0.07843 0.07547 0.07515 0.07509 0.07455\n",
      " 0.07315 0.07139 0.07137 0.07098 0.07012 0.06991 0.06914 0.06889 0.06855\n",
      " 0.06825]\n"
     ]
    }
   ],
   "source": [
    "print(query_scores[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape np array into 327 x 20000 array\n",
    "query_scores = query_scores.reshape(327, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6540000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_frame_ids = np.fromfile(\"native-queries/native-query-frame-IDs.bin\", dtype='i')\n",
    "query_frame_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5697  5645 18842 10847  4872 15282  5644 11257  3449  5380 15283     1\n",
      "  4489 17026 10845   965  5643 18845 12903  2241 19246  2226 15342  3245\n",
      "   964  8758 12083 10711 19007 14892 15213 16454  4493 16475  3725  7890\n",
      "  4927   498 10710   452  8128 14617  2564   963 19121  2810 14099  3556\n",
      " 13992  6988   980 18702  2454 14890 13953  2663 16117  8347  2453 14374\n",
      "  9795  4375   729  5819  9391 12902 10846 15811  7889 16186 10848  3451\n",
      " 17975 19951 18358 16476 18843 18686  6129  7380 12721  5267  9626 17687\n",
      " 12334 15387 14540 14911  3622  4589 12085  7879 10496  3482 14615  6905\n",
      " 10152 19706  3481  9759]\n"
     ]
    }
   ],
   "source": [
    "print(query_frame_ids[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape np array into 327 x 20000 array\n",
    "query_frame_ids = query_frame_ids.reshape(327, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_features = np.fromfile(\"native-queries/frame-features.bin\", dtype='f')\n",
    "frame_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16691  0.56416  0.32702 -0.11217  0.19371  0.5717   0.1079  -0.04373\n",
      "  0.22609  0.0775   0.14043  0.08696  0.04192 -0.00181  0.02947 -0.05099\n",
      " -0.02955 -0.00342  0.06661  0.03804  0.01074  0.07426  0.05218  0.01714\n",
      " -0.05492  0.04126 -0.06568  0.05996 -0.03729 -0.06075  0.03306 -0.02322\n",
      " -0.01536 -0.00883  0.00342  0.01878  0.04251  0.02456 -0.0076   0.01512\n",
      "  0.02498 -0.02595 -0.01833 -0.00277 -0.00717  0.00178 -0.00322  0.00384\n",
      "  0.00497  0.01047 -0.0292   0.01857  0.01496  0.01483  0.03119  0.02505\n",
      " -0.03294  0.02223 -0.0336   0.01726 -0.01783  0.00684  0.01794 -0.00201\n",
      " -0.0444  -0.01943 -0.01307 -0.00856 -0.00216  0.00839  0.00798  0.0165\n",
      "  0.02071 -0.00376  0.01017  0.01088  0.00909 -0.0092  -0.00007 -0.03174\n",
      " -0.05065  0.03829  0.00424  0.00299  0.01122 -0.01765  0.00512 -0.00211\n",
      " -0.00814 -0.04114 -0.01271  0.01588 -0.01666  0.00565  0.01208 -0.02558\n",
      " -0.01413 -0.01899 -0.02829 -0.01703]\n"
     ]
    }
   ],
   "source": [
    "print(frame_features[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape np array into 20000 x 128 array\n",
    "frame_features = frame_features.reshape(20000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOM Implementation\n",
    "\n",
    "class SOM:\n",
    "    \n",
    "    def __init__(self, som_size, data, sigma, lambda_, learning_rate, iterations):\n",
    "        \n",
    "        self.som_size = som_size\n",
    "        self.data = data\n",
    "        # sigma - radius of a neighborhood\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "        # number of iterations\n",
    "        self.iterations = iterations\n",
    "        # lambda - time constant. used to update (= decay) the radius and learning rate\n",
    "        self.lambda_ = lambda_\n",
    "        # intialize SOM with random weights\n",
    "        self.som = np.random.random((som_size, som_size, data.shape[1]))\n",
    "       \n",
    "    def update_learning_rate(self, i):\n",
    "        return self.learning_rate * np.exp(-i / self.lambda_)\n",
    "\n",
    "    def update_sigma(self, i):\n",
    "        return self.sigma * np.exp(-i / self.lambda_)\n",
    "\n",
    "    # smart implementation?\n",
    "    def neighborhood_function(self, sigma, dist):\n",
    "        return np.exp(-(dist ** 2) / (2 * (sigma ** 2)))\n",
    "    \n",
    "    # improved euclidean distance function\n",
    "    def euclidean_dist(self, x, y):\n",
    "        return spdist.cdist(x.reshape(1, -1), y.reshape(1, -1), 'euclidean').reshape(1)[0]\n",
    "    \n",
    "    # finding Best Matching Unit (TODO later: consdier ranking)\n",
    "    def find_bmu(self, vector):\n",
    "        \n",
    "        min_dist = 1e+10\n",
    "        \n",
    "        for i in range(self.som.shape[0]):\n",
    "            for j in range(self.som.shape[1]):\n",
    "                \n",
    "                dist = self.euclidean_dist(self.som[i, j], vector)\n",
    "                \n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    bmu_index = np.array([i, j])\n",
    "\n",
    "        return bmu_index\n",
    "                    \n",
    "    def train(self):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        index_list = np.random.permutation(20000)\n",
    "        \n",
    "        for random_index in index_list:\n",
    "        \n",
    "            for t in range(self.iterations):\n",
    "\n",
    "                random_input = self.data[random_index, :]\n",
    "                bmu_index = self.find_bmu(random_input)\n",
    "\n",
    "                # update learning rate and sigma with current time\n",
    "                learning_rate = self.update_learning_rate(t)\n",
    "                sigma = self.update_sigma(t)\n",
    "\n",
    "                # update the weights of BMU and its neighborhood\n",
    "                for i in range(self.som.shape[0]):\n",
    "                    for j in range(self.som.shape[1]):\n",
    "                        som_node = np.array([i,j])\n",
    "                        dist = self.euclidean_dist(som_node, bmu_index)\n",
    "                        self.som[i, j]=self.som[i,j]+learning_rate*self.neighborhood_function(sigma, dist)*(random_input-self.som[i,j])\n",
    "\n",
    "        print(\"Training complete. Time elapsed: %s seconds\" % (time.time() - start_time))\n",
    "\n",
    "    # just putting the 3 functions below together since they involve a sequence of operations\n",
    "    def display_results(self):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        filepaths = pd.read_csv(r\"C:\\Users\\KWP\\bachelor_thesis\\native-queries\\frame-ID-to-filepath.csv\", sep=' ', names=['filename', 'ID'])\n",
    "        df = self.node2image(filepaths)\n",
    "        images = self.select_images(df)\n",
    "        self.display_images(images)\n",
    "        \n",
    "        print(\"Time elapsed: %s seconds\" % (time.time() - start_time))\n",
    "    \n",
    "    def node2image(self, filepaths):\n",
    "        \n",
    "        # run find_bmu to obtain BMU for each feature vector\n",
    "        \n",
    "        bmu_list = []\n",
    "        for vec in self.data:\n",
    "            bmu_list.append(self.find_bmu(vec))\n",
    "        \n",
    "        # storing the result in a dataframe. \n",
    "        # i-th row of the dataframe (ex: 4 1) is associated with the BMU coordinates of the i-th feature vector  \n",
    "        data_ = pd.DataFrame(bmu_list, columns=['BMU_x','BMU_y'])\n",
    "        \n",
    "        # merge the 2 dataframes\n",
    "        df = pd.concat([filepaths, data_], axis=1, join='inner')\n",
    "\n",
    "        # now we have:\n",
    "        \n",
    "        # filename ID BMU_x BMU_y\n",
    "        # ........ rows ........\n",
    "        \n",
    "        # calling next function to select images \n",
    "        return df\n",
    "        \n",
    "    def select_images(self, df):\n",
    "        \n",
    "        # empty dataframe with column names\n",
    "        selected_images = pd.DataFrame(columns = ['filename', 'ID', 'BMU_x', 'BMU_y'])\n",
    "        \n",
    "        for i in range(self.som_size):\n",
    "            for j in range(self.som_size):\n",
    "                \n",
    "                tmp = df.loc[(df.BMU_x == i) & (df.BMU_y == j)]\n",
    "                    \n",
    "                if(len(tmp) != 0):\n",
    "                        \n",
    "                    ## random selection (for now) ##\n",
    "                    sample = tmp.sample()\n",
    "                    selected_images = selected_images.append(sample)\n",
    "        \n",
    "        print(\"The following images were selected: \")\n",
    "        display(selected_images)\n",
    "        \n",
    "        # calling next function to display images\n",
    "        return selected_images\n",
    "    \n",
    "    def display_images(self, selected_images):\n",
    "        \n",
    "        my_dir = \"C:/Users/KWP/bachelor_thesis/native-queries/thumbs/\"\n",
    "\n",
    "        fig, ax = plt.subplots(self.som_size, self.som_size, sharex='col', sharey='row', figsize=(200,200))\n",
    "\n",
    "        for i in range(len(selected_images)):\n",
    "    \n",
    "            row = selected_images.iloc[i,:]\n",
    "            x = row.BMU_x\n",
    "            y = row.BMU_y\n",
    "    \n",
    "            img = Image.open(my_dir + row.filename)\n",
    "            img = img.resize((320, 180))\n",
    "            img = np.asarray(img)\n",
    "    \n",
    "            ax[x, y].imshow(img)\n",
    "        \n",
    "        plt.tight_layout(pad=0.1, w_pad=0.1, h_pad=0.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Time elapsed: 345.7106411457062 seconds\n"
     ]
    }
   ],
   "source": [
    "# training SOM with size 5 x 5\n",
    "# Goal: 10 x 10\n",
    "\n",
    "size = 5\n",
    "som = SOM(som_size=5, data=frame_features, sigma=1, lambda_=1e2, learning_rate=0.5, iterations=10)\n",
    "\n",
    "som.train()\n",
    "\n",
    "#%lprun -f SOM.train som.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
