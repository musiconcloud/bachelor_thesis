{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcfa264-e9be-431d-a165-b4803b7b0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/andremsouza/python-som\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Union, Callable, Tuple, Iterable\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import ndcg_score, dcg_score\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from time import time\n",
    "from itertools import product\n",
    "from munkres import Munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa049286-de91-4180-8f45-e8f604d94c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _asymptotic_decay(x: float, t: int, max_t: int) -> float:\n",
    "    \"\"\"\n",
    "    Asymptotic decay function. Can be used for both the learning_rate or the neighborhood_radius.\n",
    "    :param x: float: Initial x parameter\n",
    "    :param t: int: Current iteration\n",
    "    :param max_t: int: Maximum number of iterations\n",
    "    :return: float: Current state of x after t iterations\n",
    "    \"\"\"\n",
    "    return x / (1 + t / (max_t / 2))\n",
    "\n",
    "\n",
    "def _linear_decay(x: float, t: int, max_t: int) -> float:\n",
    "    \"\"\"\n",
    "    Linear decay function. Can be used for both the learning_rate or the neighborhood_radius.\n",
    "    :param x: float: Initial x parameter\n",
    "    :param t: int: Current iteration\n",
    "    :param max_t: int: Maximum number of iterations\n",
    "    :return: float: Current state of x after t iterations\n",
    "    \"\"\"\n",
    "    return x * (1.0 - t / max_t)\n",
    "\n",
    "def _euclidean_distance(a: Union[float, np.ndarray], b: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n",
    "    return np.linalg.norm(np.subtract(a, b), ord=2, axis=-1)\n",
    "\n",
    "def direct_neighbours(cell, size):\n",
    "    for c in product(*(range(n-1, n+2) for n in cell)):\n",
    "        if c != cell and all(0 <= n < size for n in c):\n",
    "            yield c\n",
    "\n",
    "class SOM:   \n",
    "    \"\"\"\n",
    "    Features:\n",
    "        - Stepwise and batch training\n",
    "        - Random weight initialization\n",
    "        - Random sampling weight initialization\n",
    "        - Linear weight initialization (with PCA)\n",
    "        - Automatic selection of map size ratio (with PCA)\n",
    "        - Gaussian and Bubble neighborhood functions\n",
    "        - Support for custom decay functions\n",
    "        - Support for visualization (U-matrix, activation matrix)\n",
    "        - Support for supervised learning (label map)\n",
    "        - Support for NumPy arrays, Pandas DataFrames and regular lists of values\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            x: Union[int, None],\n",
    "            y: Union[int, None],\n",
    "            input_len: int,\n",
    "            learning_rate: float = 0.5,\n",
    "            learning_rate_decay: Callable[[float, int, int], float] = _asymptotic_decay,\n",
    "            neighborhood_radius: float = 1.0,\n",
    "            neighborhood_radius_decay: Callable[[float, int, int], float] = _asymptotic_decay,\n",
    "            neighborhood_function: str = 'gaussian',\n",
    "            distance_function: Callable[\n",
    "                [Union[float, np.ndarray], Union[float, np.ndarray]], Union[float, np.ndarray]] = _euclidean_distance,\n",
    "            random_seed: Union[int, None] = None,\n",
    "            data: Union[np.ndarray, pd.DataFrame, list, None] = None,\n",
    "        \n",
    "            auto_var_adjustment=False, \n",
    "            var_param=0, \n",
    "            num_images=20000, \n",
    "            query_scores=np.zeros(shape=(20000,)), \n",
    "            frame_ids=np.zeros(shape=(20000,))\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the self-organizing map class.\n",
    "        :param x: int or NoneType: X dimension of the self-organizing map\n",
    "        :param y: int or NoneType: Y dimension of the self-organizing map\n",
    "        :param input_len: int: Number of features of the training dataset, i.e.,\n",
    "            number of elements of each node of the network.\n",
    "        :param learning_rate: float: Initial learning rate for the training process. Defaults to 0.5.\n",
    "            Note: The value of the learning_rate is irrelevant for the 'batch' training mode.\n",
    "        :param learning_rate_decay: function: Decay function for the learning_rate variable.\n",
    "            May be a predefined one from this package, or a custom function, with the same parameters and return type.\n",
    "            Defaults to _asymptotic_decay.\n",
    "        :param neighborhood_radius: float: Initial neighborhood radius for the training process. Defaults to 1.\n",
    "        :param neighborhood_radius_decay: function: Decay function for the neighborhood_radius variable.\n",
    "            May be a predefined one from this package, or a custom function, with the same parameters and return type.\n",
    "            Defaults to _asymptotic_decay\n",
    "        :param neighborhood_function: str: Neighborhood function name for the training process.\n",
    "            May be either 'gaussian' or 'bubble'.\n",
    "        :param distance_function: function: Function for calculating distances/dissimilarities between models of the\n",
    "            network.\n",
    "            May be a predefined one from this package, or a custom function, with the same parameters and return type.\n",
    "            Defaults to _euclidean_distance.\n",
    "        :param random_seed: int or None: Seed for NumPy random value generator. Defaults to None.\n",
    "        :param data: array-like: dataset for performing PCA.\n",
    "            Required when either x or y is None, for determining map size.\n",
    "        \"\"\"\n",
    "        \n",
    "        if (x, y) == (None, None):\n",
    "            raise ValueError('At least one of the dimensions (x, y) must be specified')\n",
    "        if x == None or y == None:\n",
    "            # If a dataset was given through **kwargs, select missing dimension with PCA\n",
    "            # The ratio of the (x, y) sizes will comply roughly with the ratio of the two largest principal components\n",
    "            if 'data' == None:\n",
    "                raise ValueError(\n",
    "                    \"If one of the dimensions is not specified, a dataset must be provided for automatic size \"\n",
    "                    \"initialization.\")\n",
    "        # Convert data to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data_array = data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "\n",
    "        # Update missing size variable\n",
    "        if x == None:\n",
    "            x = y // ratio\n",
    "        if y == None:\n",
    "            y = x // ratio\n",
    "            \n",
    "        # Initializing private variables\n",
    "        self.som_size = x\n",
    "        \n",
    "        self._shape = (np.uint(x), np.uint(y))\n",
    "        self._input_len = np.uint(input_len)\n",
    "        self._learning_rate = float(learning_rate)\n",
    "        self._learning_rate_decay = learning_rate_decay\n",
    "        self._neighborhood_radius = float(neighborhood_radius)\n",
    "        self._neighborhood_radius_decay = neighborhood_radius_decay\n",
    "        self._neighborhood_function = {\n",
    "            'gaussian': self._gaussian}[neighborhood_function]\n",
    "        self._distance_function = distance_function\n",
    "        self._neigx, self._neigy = np.arange(self._shape[0]), np.arange(self._shape[1])\n",
    "        \n",
    "        self.data = data\n",
    "        self.query_scores = query_scores\n",
    "        self.num_images = num_images\n",
    "        \n",
    "        # empty dataframe with column names\n",
    "        self.selected_images = pd.DataFrame(columns = ['filename', 'ID', 'BMU_x', 'BMU_y'])\n",
    "        self.selected_vectors = np.zeros((x, y, 128))\n",
    "        \n",
    "        # Seed numpy random generator\n",
    "        if random_seed == None:\n",
    "            self._random_seed = np.random.randint(np.random.randint(np.iinfo(np.int32).max))\n",
    "        else:\n",
    "            self._random_seed = int(random_seed)\n",
    "        np.random.seed(self._random_seed)\n",
    "\n",
    "        ## using top N images only! ##\n",
    "        if num_images != 20000:\n",
    "            \n",
    "            ids = pd.DataFrame(frame_ids, columns=['ID'])\n",
    "            ids = ids[0:num_images]\n",
    "            \n",
    "            self.data = data[ids.ID]\n",
    "        \n",
    "        # Random weight initialization\n",
    "        self._weights = np.random.standard_normal(size=(self._shape[0], self._shape[1], self._input_len))\n",
    "        \n",
    "        # adding extra dimension to the data\n",
    "        # random initialization\n",
    "        if auto_var_adjustment == True or var_param > 0: \n",
    " \n",
    "            self.data = np.append(self.data, np.zeros((num_images, 1)), axis=1)\n",
    "            \n",
    "            self.adjust_var()\n",
    "            self.initial_bias()\n",
    "        \n",
    "    ## custom functions for adding bias to SOM initialization ## \n",
    "    def adjust_var(self):\n",
    "        # variance of randomly initialized SOM nodes (on original features)\n",
    "        sum = 0\n",
    "        for i in range(self.som_size):\n",
    "            for j in range(self.som_size):\n",
    "                sum += self._weights[i, j].var()\n",
    "        print(\"sum of variance over all SOM nodes' original features: {}\".format(sum))\n",
    "            \n",
    "        # if the var difference is low enough, then we adjust the query scores\n",
    "        for i in range(10000):\n",
    "            \n",
    "            tmp = self.query_scores * i\n",
    "\n",
    "            if abs(sum - tmp.var()) < 0.1:\n",
    "                \n",
    "                print(\"variance of adjusted query scores: {}\".format(tmp.var()))\n",
    "                break\n",
    "                \n",
    "        self.query_scores = tmp\n",
    "        \n",
    "    def initial_bias(self):\n",
    "\n",
    "        # add query scores to SOM as another feature, considering the position of the nodes\n",
    "\n",
    "        # we will divide query_scores into N intervals of equal size (where SOM has size n x n)\n",
    "        # then from each interval corresponding to each row, pick N values randomly.\n",
    "\n",
    "        # for example, for 5 x 5 SOM: divide query_score into 5 intervals\n",
    "        # top 80~100% values, 60~80%, ..., 0~20%. Nodes in top row are assigned 5 random values from the first interval, and so on.\n",
    "\n",
    "        cutpoints = []\n",
    "        interval_size = 100 / self.som_size \n",
    "        for i in range(1, self.som_size):\n",
    "\n",
    "            cutpoint = np.quantile(self.query_scores, interval_size * i * 0.01)\n",
    "            cutpoints.append(cutpoint)\n",
    "            \n",
    "            if i == 1:\n",
    "\n",
    "                bottom_interval = self.query_scores[self.query_scores < cutpoint]\n",
    "                \n",
    "                # assign to bottom nodes i.e. som[size-1, 0] ... som[size-1, size-1]\n",
    "                for j in range(self.som_size):\n",
    "                    self._weights[self.som_size-1, j, 128] = np.random.choice(bottom_interval, size=1)[0]\n",
    "\n",
    "            else:\n",
    "                interval = self.query_scores[np.logical_and(self.query_scores > cutpoints[i-2], self.query_scores < cutpoint)]\n",
    "                \n",
    "                # assign to middle row nodes e.g. som[1, 0] ... som[1, size-1]\n",
    "                for j in range(self.som_size):\n",
    "                    self._weights[self.som_size-i, j, 128] = np.random.choice(interval, size=1)[0]\n",
    "\n",
    "                if i == self.som_size-1:\n",
    "\n",
    "                    top_interval = self.query_scores[self.query_scores > cutpoint]         \n",
    "\n",
    "                    # assign to top nodes i.e. som[0, 0] ... som[0, size-1]\n",
    "                    for j in range(self.som_size):\n",
    "\n",
    "                        self._weights[0, j, 128] = np.random.choice(top_interval, size=1)[0]\n",
    "\n",
    "    # remove the extra dimension added to the data \n",
    "    def reset_data(self):\n",
    "        # return? or modify via class directly?\n",
    "        self.data = np.delete(self.data, -1, axis=1)\n",
    "\n",
    "    def get_weights(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gets the weight matrix of the network.\n",
    "        :return: np.ndarray: Weight matrix of the network.\n",
    "        \"\"\"\n",
    "        return self._weights\n",
    "\n",
    "    def activate(self, x: Union[np.ndarray, pd.DataFrame, list]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculates distances between an instance x and the weights of the network.\n",
    "        :param x: array-like: Instance to be compared with the weights of the network.\n",
    "        :return: np.ndarray: Distances between x and each weight of the network.\n",
    "        \"\"\"\n",
    "        return self._distance_function(x, self._weights)\n",
    "\n",
    "    def winner(self, x: Union[np.ndarray, pd.DataFrame, list]) -> Union[Iterable, Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Calculates the best-matching unit of the network for an instance x\n",
    "        :param x: array-like: Instance to be compared with the weights of the network.\n",
    "        :return: (int, int): Index of the best-matching unit of x.\n",
    "        \"\"\"\n",
    "        activation_map = self.activate(x)\n",
    "        return np.unravel_index(activation_map.argmin(), activation_map.shape)\n",
    "\n",
    "    def quantization(self, data: Union[np.ndarray, pd.DataFrame, list]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculates distances from each instance of 'data' to each of the weights of the network.\n",
    "        :param data: array-like: Dataset to be compared with the weights of the network.\n",
    "        :return: np.ndarray: array of lists of distances from each instance of the dataset\n",
    "            to each weight of the network.\n",
    "        \"\"\"\n",
    "        # Convert data to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data_array = data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "        return np.array([(self._distance_function(i, self._weights[self.winner(i)])) for i in data_array])\n",
    "\n",
    "    def quantization_error(self, data: Union[np.ndarray, pd.DataFrame, list]) -> float:\n",
    "        \"\"\"\n",
    "        Calculates average distance of the weights of the network to their assigned instances from data.\n",
    "        This error is a quality measure for the training process.\n",
    "        :param data: array-like: Dataset to be compared with the weights of the network.\n",
    "        :return: float: Quantization error.\n",
    "        \"\"\"\n",
    "        quantization = self.quantization(data)\n",
    "        return quantization.mean()\n",
    "\n",
    "    def activation_matrix(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculates the activation matrix of the network for a dataset, i.e., for each node, the count of instances that\n",
    "        have been assigned to it, in the current state.\n",
    "        :param data: array-like: Dataset to be compared with the weights of the network.\n",
    "        :return: np.ndarray: Activation matrix.\n",
    "        \"\"\"\n",
    "        # Convert data to numpy array\n",
    "        if isinstance(self.data, pd.DataFrame):\n",
    "            data_array = self.data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(self.data)\n",
    "\n",
    "        activation_matrix = np.zeros(self._shape)\n",
    "        for i in data_array:\n",
    "            activation_matrix[self.winner(i)] += 1\n",
    "        return activation_matrix\n",
    "    \n",
    "    def winner_map(self, data: Union[np.ndarray, pd.DataFrame, list]) -> dict:\n",
    "        \"\"\"\n",
    "        Calculates, for each node (i, j) of the network,\n",
    "        the list of all instances from 'data' that has been assigned to it.\n",
    "        :param data: array-like: Dataset to be compared with the weights of the network.\n",
    "        :return: dict: Winner map.\n",
    "        \"\"\"\n",
    "        # Convert data to numpy array\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data_array = data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "        winner_map = {(i, j): [] for i in range(self._shape[0]) for j in range(self._shape[1])}\n",
    "        for i in data_array:\n",
    "            winner_map[self.winner(i)].append(i)\n",
    "        return winner_map\n",
    "\n",
    "    def train(self, n_iteration: Union[int, None] = None,\n",
    "              mode: str = 'sequential', verbose: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Trains the self-organizing map, with the dataset 'data', and a certain number of iterations.\n",
    "        :param data: array-like: Dataset for training.\n",
    "        :param n_iteration: int or None: Number of iterations of training.\n",
    "            If None, defaults to 1000 * len(data) for stepwise training modes,\n",
    "            or 10 * len(data) for batch training mode.\n",
    "        :param mode: str: Training mode name. May be either 'random', 'sequential', or 'batch'.\n",
    "            For 'batch' mode, a much smaller number of iterations is needed, but a higher computation power is required\n",
    "            for each individual iteration.\n",
    "        :param verbose: bool: Activate to print useful information to the terminal/console, e.g.,\n",
    "            the progress of the training process\n",
    "        :return: float: Quantization error after training\n",
    "        \"\"\"\n",
    "        # Convert data to numpy array for training\n",
    "        if isinstance(self.data, pd.DataFrame):\n",
    "            data_array = self.data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(self.data)\n",
    "\n",
    "        # If no number of iterations is given, select automatically\n",
    "        if n_iteration == None:\n",
    "            n_iteration = {'random': 1000, 'sequential': 1000, 'batch': 10}[mode] * len(data_array)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Training with\", n_iteration,\n",
    "                  \"iterations.\\nTraining mode:\", mode, sep=' ')\n",
    "\n",
    "        elif mode == 'sequential':\n",
    "            # Sequential sampling from training dataset\n",
    "            for it, i in enumerate(data_array):\n",
    "                # Calculating decaying alpha and sigma parameters for updating weights\n",
    "                alpha = self._learning_rate_decay(self._learning_rate, it, n_iteration)\n",
    "                sigma = self._neighborhood_radius_decay(\n",
    "                    self._neighborhood_radius, it, n_iteration)\n",
    "\n",
    "                # Finding winner node (best-matching unit)\n",
    "                winner = self.winner(i)\n",
    "\n",
    "                # Updating weights, based on current neighborhood function\n",
    "                self._weights += alpha * self._neighborhood_function(winner, sigma)[..., None] * (\n",
    "                        i - self._weights)\n",
    "\n",
    "                # Print progress, if verbose is activated\n",
    "                if verbose:\n",
    "                    print(\"Iteration:\", it, \"/\", n_iteration, sep=' ', end='\\r', flush=True)\n",
    "                    \n",
    "        elif mode == 'batch':\n",
    "            # Batch training\n",
    "            for it in range(n_iteration):\n",
    "\n",
    "                # Calculating decaying sigma\n",
    "                sigma = self._neighborhood_radius_decay(\n",
    "                    self._neighborhood_radius, it, n_iteration)\n",
    "\n",
    "                # For each node, create a list of instances associated to it\n",
    "                winner_map = self.winner_map(data_array)\n",
    "\n",
    "                # Calculate the weighted average of all instances in the neighborhood of each node\n",
    "                new_weights = np.zeros(self._weights.shape)\n",
    "                for i in winner_map.keys():\n",
    "                    neig = self._neighborhood_function(i, sigma)\n",
    "                    upper, bottom = np.zeros(self._input_len), 0.0\n",
    "                    for j in winner_map.keys():\n",
    "                        upper += neig[j] * np.sum(winner_map[j], axis=0)\n",
    "                        bottom += neig[j] * len(winner_map[j])\n",
    "\n",
    "                    # Only update if there is any instance associated with the winner node or its neighbors\n",
    "                    if bottom != 0:\n",
    "                        new_weights[i] = upper / bottom\n",
    "\n",
    "                # Update all nodes concurrently\n",
    "                self._weights = new_weights\n",
    "\n",
    "                # Print progress, if verbose is activated\n",
    "                if verbose:\n",
    "                    print(\"Iteration:\", it, \"/\", n_iteration, sep=' ', end='\\r', flush=True)\n",
    "        else:\n",
    "            # Invalid training mode value\n",
    "            raise ValueError(\n",
    "                \"Invalid value for 'mode' parameter. Value should be in \" + str(['random', 'sequential', 'batch']))\n",
    "\n",
    "        # Compute quantization error\n",
    "        q_error = self.quantization_error(data_array)\n",
    "        if verbose:\n",
    "            print(\"Quantization error:\", q_error, sep=' ')\n",
    "        return q_error\n",
    "\n",
    "    def weight_initialization(self, mode: str = 'random',\n",
    "                              **kwargs: Union[np.ndarray, pd.DataFrame, list, str, int]) -> None:\n",
    "        \"\"\"\n",
    "        Function for weight initialization of the self-organizing map. Calls other methods for each initialization mode.\n",
    "        :param mode: str: Initialization mode. May be either 'random', 'linear', or 'sample'.\n",
    "            Note: Each initialization method may require multiple additional arguments in kwargs.\n",
    "        :param kwargs:\n",
    "            For 'random' initialization mode, 'sample_mode': str may be provided to determine the sampling mode.\n",
    "            'sample_mode' may be either 'standard_normal' (default) or 'uniform'.\n",
    "            For 'random' and 'sample' modes, 'random_seed': int may be provided for the random value generator.\n",
    "            For 'sample' and 'linear' modes, 'data': array-like must be provided for sampling/PCA.\n",
    "        \"\"\"\n",
    "        modes = {'random': self._weight_initialization_random,\n",
    "                 'sample': self._weight_initialization_sample}\n",
    "        try:\n",
    "            modes[mode](**kwargs)\n",
    "        except KeyError:\n",
    "            raise ValueError(\"Invalid value for 'mode' parameter. Value should be in \" + str(modes.keys()))\n",
    "\n",
    "    def _weight_initialization_random(self, sample_mode: str = 'standard_normal',\n",
    "                                      random_seed: Union[int, None] = None) -> None:\n",
    "        \"\"\"\n",
    "        Random initialization method. Assigns weights from a random distribution defined by 'sample_mode'.\n",
    "        :param sample_mode: str: Distribution for random sampling. May be either 'uniform' or 'standard_normal'.\n",
    "            Defaults to 'standard_normal'.\n",
    "        :param random_seed: int or None: Seed for NumPy random value generator. Defaults to None.\n",
    "        \"\"\"\n",
    "        sample_modes = {'uniform': np.random.random, 'standard_normal': np.random.standard_normal}\n",
    "\n",
    "        # Seed numpy random generator\n",
    "        if random_seed == None:\n",
    "            random_seed = np.random.randint(\n",
    "                np.random.randint(np.iinfo(np.int32).max))\n",
    "        else:\n",
    "            random_seed = int(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        # Initialize weights randomly\n",
    "        try:\n",
    "            self._weights = sample_modes[sample_mode](size=self._weights.shape)\n",
    "        except KeyError:\n",
    "            raise ValueError(\n",
    "                \"Invalid value for 'sample_mode' parameter. Value should be in \" + str(sample_modes.keys()))\n",
    "\n",
    "    def _weight_initialization_sample(self, data: Union[np.ndarray, pd.DataFrame, list],\n",
    "                                      random_seed: Union[int, None] = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialization method. Assigns weights to random samples from an input dataset.\n",
    "        :param data: Dataset for weight initialization/sampling.\n",
    "        :param random_seed: int or None: Seed for NumPy random value generator. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Seed numpy random generator\n",
    "        if random_seed == None:\n",
    "            random_seed = np.random.randint(\n",
    "                np.random.randint(np.iinfo(np.int32).max))\n",
    "        else:\n",
    "            random_seed = int(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        # Convert data to numpy array for training\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data_array = data.to_numpy()\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "\n",
    "        # Assign weights to random samples from dataset\n",
    "        sample_size = self._shape[0] * self._shape[1]\n",
    "        sample = np.random.choice(len(data_array), size=sample_size,\n",
    "                                  replace=(sample_size > len(data_array)))\n",
    "        self._weights = data_array[sample].reshape(self._weights.shape)\n",
    "\n",
    "    def _gaussian(self, c: Tuple[int, int], sigma: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gaussian neighborhood function, centered in c. \n",
    "        :param c: (int, int): Center coordinates for gaussian function.\n",
    "        :param sigma: float: Spread variable for gaussian function.\n",
    "        :return: np.ndarray: Gaussian, centered in c, over all the weights of the network.\n",
    "        \"\"\"\n",
    "        # Calculate coefficient with sigma\n",
    "        d = 2 * sigma * sigma\n",
    "        # Calculate vertical and horizontal distances\n",
    "        dx = self._neigx - c[0]\n",
    "        dy = self._neigy - c[1]\n",
    "\n",
    "        # Calculate gaussian centered in c\n",
    "        ax = np.exp(-np.power(dx, 2) / d)\n",
    "        ay = np.exp(-np.power(dy, 2) / d)\n",
    "        return np.outer(ax, ay)\n",
    "    \n",
    "    \n",
    "    ## custom functions for displaying images ##\n",
    "    \n",
    "    def display_results(self, frameID_scores, original_data, ranking=False):\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        # putting the 3 functions below together\n",
    "        filepaths = pd.read_csv(r\"native-queries\\frame-ID-to-filepath.csv\",sep=' ',names=['filename', 'ID'])\n",
    "        \n",
    "        if self.num_images == (self.som_size * self.som_size):\n",
    "            self.hungarian_algo(filepaths, frameID_scores)\n",
    "        \n",
    "        else:\n",
    "            df = self.node2image(filepaths)\n",
    "            self.select_images(df, frameID_scores)\n",
    "        \n",
    "        self.display_images(original_data)\n",
    "        \n",
    "        if ranking == True:\n",
    "            self.add_ranking()\n",
    "\n",
    "        print(\"Time elapsed: %s seconds\" % (time() - start_time))\n",
    "    \n",
    "    def hungarian_algo(self, filepaths, frameID_scores):\n",
    "        \n",
    "        frameID_scores = frameID_scores[0:self.num_images]\n",
    "        # self.selected_images = pd.DataFrame(columns = ['filename', 'ID', 'BMU_x', 'BMU_y'])\n",
    "        \n",
    "        # merge with filepaths on top 100 IDs only \n",
    "        merged = frameID_scores.merge(filepaths, how='inner', on='ID') \n",
    "    \n",
    "        # pairwise distance matrix for SOM weight vectors and input data \n",
    "        pairwise_dist = distance_matrix(np.concatenate(self._weights), self.data)\n",
    "        m = Munkres()\n",
    "        indexes = m.compute(pairwise_dist)\n",
    "\n",
    "        my_pd = pd.DataFrame(columns = ['ID', 'BMU_x', 'BMU_y'])\n",
    "\n",
    "        for row, column in indexes:\n",
    "\n",
    "            x = row / 10\n",
    "            y = row % 10\n",
    "            my_pd = my_pd.append({'ID': merged.ID[column],'BMU_x': int(x), 'BMU_y': y}, ignore_index=True)\n",
    "\n",
    "        merged = my_pd.merge(merged, on='ID')\n",
    "        \n",
    "        print(\"The following images were selected by Hungarian Algo: \")\n",
    "        display(merged)\n",
    "        \n",
    "        self.selected_images = merged\n",
    "    \n",
    "    def node2image(self, filepaths):\n",
    "\n",
    "        # run find_bmu to obtain BMU for each feature vector\n",
    "\n",
    "        bmu_list = []\n",
    "        for vec in self.data:\n",
    "            bmu_list.append(np.asarray(self.winner(vec)))\n",
    "\n",
    "        # storing the result in a dataframe. \n",
    "        # i-th row of the dataframe (ex: 4 1) is associated with the BMU coordinates of the i-th feature vector  \n",
    "        data_ = pd.DataFrame(bmu_list, columns=['BMU_x','BMU_y'])\n",
    "\n",
    "        # merge the 2 dataframes\n",
    "        df = pd.concat([filepaths, data_], axis=1, join='inner')\n",
    "\n",
    "        # now we have:\n",
    "\n",
    "        # filename ID BMU_x BMU_y\n",
    "        # ........ rows ........\n",
    "\n",
    "        return df\n",
    "\n",
    "    # image selection after training\n",
    "    def select_images(self, df, id_scores):\n",
    "\n",
    "        # empty dataframe with column names\n",
    "        ##selected_images = self.selected_images\n",
    "        selected_images = pd.DataFrame(columns = ['filename', 'ID', 'BMU_x', 'BMU_y'])\n",
    "        \n",
    "        for i in range(self.som_size):\n",
    "            for j in range(self.som_size):\n",
    "\n",
    "                tmp = df.loc[(df.BMU_x == i) & (df.BMU_y == j)]\n",
    "\n",
    "                if(len(tmp) != 0):\n",
    "                    \n",
    "                    merged = tmp.merge(id_scores, how='inner', on='ID') \n",
    "                    \n",
    "                    # select image with highest score\n",
    "                    highest = merged.loc[merged['query_scores'].idxmax()]\n",
    "                    \n",
    "                    selected_images = selected_images.append(highest)\n",
    "\n",
    "        print(\"The following images were selected: \")\n",
    "        display(selected_images)\n",
    "\n",
    "        self.selected_images = selected_images\n",
    "    \n",
    "    def display_images(self, original_data):\n",
    "\n",
    "        # this function not only displays images, but also removes the extra dimension we added to the data\n",
    "        # and extracts selected vectors for each SOM node\n",
    "        \n",
    "        my_dir = \"native-queries/thumbs/\"\n",
    "\n",
    "        \n",
    "        \n",
    "        # fig, ax = plt.subplots(self.som_size, self.som_size, sharex='col', sharey='row', figsize=(320,180))\n",
    "\n",
    "        \n",
    "        \n",
    "        # remove the extra dimension we initially added to the data\n",
    "        if(self._input_len == 129):\n",
    "            self.reset_data()\n",
    "        for i in range(len(self.selected_images)):\n",
    "\n",
    "            row = self.selected_images.iloc[i,:]\n",
    "            x = row.BMU_x\n",
    "            y = row.BMU_y\n",
    "            id = row.ID\n",
    "        \n",
    "            # extracting selected vectors used for output - for evaluation purposes later\n",
    "            self.selected_vectors[x, y] = original_data[id]\n",
    "    \n",
    "        \"\"\"\n",
    "            img = Image.open(my_dir + row.filename)\n",
    "            img = img.resize((320, 180))\n",
    "            img = np.asarray(img)\n",
    "\n",
    "            ax[x, y].imshow(img)\n",
    "\n",
    "        plt.tight_layout(pad=0.1, w_pad=0.1, h_pad=0.1)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "   # adding ranking to selected images \n",
    "    def add_ranking(self):\n",
    "        \n",
    "        selected = self.selected_images\n",
    "        \n",
    "        selected['SOM_rank'] = np.arange(len(selected)) + 1\n",
    "        selected['QS_rank'] = selected['query_scores'].rank(ascending=False).astype(int)\n",
    "    \n",
    "        self.selected_images = selected\n",
    "        \n",
    "        print(\"ranking: \")\n",
    "        display(selected)\n",
    " \n",
    "    ## evaluation metrics ## \n",
    "    # comparing the distance of selected images on the output screen and in the feature space\n",
    "    \n",
    "    # here we use 2 different notions of \"neighbor\" - direct neighbors (neighbors in all cardinal directions) and next door neighbors.\n",
    "    def mean_distance(self, print_result=False):\n",
    "        # mean distance matrix[i,j] contains the mean distance of neighbors from selected_vectors[i, j]\n",
    "        mean_distance_matrix = np.zeros((self.som_size, self.som_size))\n",
    "        \n",
    "        distance_sum = 0\n",
    "        \n",
    "        for i in range(self.som_size):\n",
    "            for j in range(self.som_size):\n",
    "                for index in list(direct_neighbours((i,j), self.som_size)):\n",
    "\n",
    "                    distance_sum += self._distance_function(self.selected_vectors[index], self.selected_vectors[i, j])\n",
    "                distance_sum /= len(list(direct_neighbours((i,j), self.som_size)))\n",
    "                mean_distance_matrix[i, j] = distance_sum\n",
    "        \n",
    "        if print_result == True:\n",
    "            print(\"mean_distance_matrix: \\n\")\n",
    "            print(mean_distance_matrix)\n",
    "            \n",
    "        return mean_distance_matrix\n",
    "                \n",
    "    def mean_distance_nextdoor(self, print_result=False):\n",
    "        \n",
    "        mean_distance_matrix = np.zeros((self.som_size, self.som_size))\n",
    "        \n",
    "        for i in range(self.som_size):\n",
    "            for j in range(self.som_size):\n",
    "                if j == 0:\n",
    "                    mean_distance_matrix[i, j] = self._distance_function(self.selected_vectors[i,j+1], self.selected_vectors[i, j])\n",
    "                elif j == self.som_size-1:\n",
    "                    mean_distance_matrix[i, j] = self._distance_function(self.selected_vectors[i, j-1], self.selected_vectors[i, j])\n",
    "                else:\n",
    "                    mean_distance_matrix[i, j] = self._distance_function(self.selected_vectors[i, j-1], self.selected_vectors[i, j]) \n",
    "                    + self._distance_function(self.selected_vectors[i, j+1], self.selected_vectors[i, j])\n",
    "                    mean_distance_matrix[i, j] /= 2\n",
    "                    \n",
    "        if print_result == True:\n",
    "            print(\"\\nmean_distance_nextdoor: \\n\")\n",
    "            print(mean_distance_matrix)\n",
    "                    \n",
    "        return mean_distance_matrix\n",
    "    \n",
    "    ## Rank correlation metrics ## \n",
    "    # comparing the original ranking with SOM-induced ranking\n",
    "        \n",
    "    def tau(self):\n",
    "            \n",
    "        return self.selected_images['SOM_rank'].corr(self.selected_images['QS_rank'], method='kendall')\n",
    "\n",
    "    def nDCG(self):\n",
    "        ## use original scores, not rankings. ##\n",
    "    \n",
    "        # Releveance scores in actual order\n",
    "        actual = self.selected_images['query_scores']\n",
    "        # in ideal order\n",
    "        ideal = actual.sort_values()\n",
    "        \n",
    "        actual = np.asarray(actual).reshape(1,100)\n",
    "        ideal = np.asarray(ideal).reshape(1, 100)\n",
    "\n",
    "        return ndcg_score(actual, ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7da86c-652e-4948-953b-00bf377f58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_scores = np.fromfile(\"native-queries/native-query-scores.bin\", dtype='f')\n",
    "query_scores = query_scores.reshape(327, 20000)\n",
    "\n",
    "frame_ids = np.fromfile(\"native-queries/native-query-frame-IDs.bin\", dtype='i')\n",
    "frame_ids = frame_ids.reshape(327, 20000)\n",
    " \n",
    "frame_features = np.fromfile(\"native-queries/frame-features.bin\", dtype='f')\n",
    "frame_features = frame_features.reshape(20000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76d5058-308c-4d67-9b92-1800c57713ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM(x=10, y=10, input_len=128, learning_rate=0.5, neighborhood_radius=1.0,\n",
    "        neighborhood_function='gaussian', data=frame_features, random_seed=1903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70090f44-382c-436d-9d3d-1249e1b77c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of variance over all SOM nodes' original features: 98.94712212304543\n",
      "variance of adjusted query scores: 98.86817932128906\n"
     ]
    }
   ],
   "source": [
    "biased_som = SOM(x=10, y=10, input_len=129, neighborhood_function='gaussian', data=frame_features, random_seed=1903, \n",
    "             auto_var_adjustment=True, num_images=100, query_scores=query_scores[0], frame_ids=frame_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffb86ac-7aa4-43b1-9f89-69f58ad3badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303661286288043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som.train(mode='sequential', n_iteration=40000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916e6041-fc5f-4bb5-8109-ac72308d2b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389408935151962"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_som.train(mode='sequential', n_iteration=40000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4484d784-110e-4545-84e2-614dbd76d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220., 207., 139., 130., 297., 470., 248., 308., 159., 172.],\n",
       "       [258., 173., 328., 315., 264., 173., 158., 149.,  89., 148.],\n",
       "       [ 69., 223.,  94., 110.,  56., 167., 132., 149., 119., 160.],\n",
       "       [ 25., 301., 186., 117., 105., 176., 225., 190., 141., 160.],\n",
       "       [353., 472., 172., 295., 187., 171., 129., 343., 309., 165.],\n",
       "       [264., 172., 153.,  94., 182., 155.,  97., 209., 250., 375.],\n",
       "       [157., 389., 109., 151., 174., 233., 124., 139., 173., 131.],\n",
       "       [216., 188., 233., 182., 122., 134., 239., 199., 174., 175.],\n",
       "       [315., 169., 381., 240., 243., 223., 456., 120., 152., 188.],\n",
       "       [350., 341., 264., 144., 272., 165., 107.,  73., 177., 121.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som.activation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a122f3e-6c3f-4c32-a744-c55058f0ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  4.,  1.,  4.,  4.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  4.,  3.,  3.,  2.,  3.,  2.,  0.],\n",
       "       [ 0.,  0.,  0.,  2.,  5.,  1.,  0.,  2.,  2.,  0.],\n",
       "       [ 0.,  0.,  0.,  4., 10., 21.,  4.,  8., 11.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_som.activation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d27867e-796d-4db1-b604-f907a8ce972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following images were selected: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ID</th>\n",
       "      <th>BMU_x</th>\n",
       "      <th>BMU_y</th>\n",
       "      <th>query_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>v04582_s00192(f017354-f017429)_g00297_f017400.jpg</td>\n",
       "      <td>12773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>v06055_s00202(f036886-f037073)_g00290_f037072.jpg</td>\n",
       "      <td>16897</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>v06692_s00061(f009716-f009776)_g00088_f009758.jpg</td>\n",
       "      <td>18661</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v00382_s00002(f003291-f006109)_g00050_f005544.jpg</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>v05326_s00001(f001841-f013458)_g00225_f008121.jpg</td>\n",
       "      <td>14890</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>v04803_s00535(f028723-f028786)_g00639_f028771.jpg</td>\n",
       "      <td>13417</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>v01419_s00073(f003647-f003677)_g00102_f003675.jpg</td>\n",
       "      <td>3885</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>v01037_s00006(f001673-f001732)_g00011_f001708.jpg</td>\n",
       "      <td>2800</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>v05033_s00074(f004550-f004599)_g00091_f004575.jpg</td>\n",
       "      <td>14099</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.12221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>v02098_s00013(f002609-f003250)_g00087_f003116.jpg</td>\n",
       "      <td>5697</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename     ID BMU_x BMU_y  \\\n",
       "133  v04582_s00192(f017354-f017429)_g00297_f017400.jpg  12773     0     0   \n",
       "175  v06055_s00202(f036886-f037073)_g00290_f037072.jpg  16897     0     1   \n",
       "127  v06692_s00061(f009716-f009776)_g00088_f009758.jpg  18661     0     2   \n",
       "6    v00382_s00002(f003291-f006109)_g00050_f005544.jpg   1096     0     3   \n",
       "214  v05326_s00001(f001841-f013458)_g00225_f008121.jpg  14890     0     4   \n",
       "..                                                 ...    ...   ...   ...   \n",
       "112  v04803_s00535(f028723-f028786)_g00639_f028771.jpg  13417     9     5   \n",
       "17   v01419_s00073(f003647-f003677)_g00102_f003675.jpg   3885     9     6   \n",
       "13   v01037_s00006(f001673-f001732)_g00011_f001708.jpg   2800     9     7   \n",
       "122  v05033_s00074(f004550-f004599)_g00091_f004575.jpg  14099     9     8   \n",
       "35   v02098_s00013(f002609-f003250)_g00087_f003116.jpg   5697     9     9   \n",
       "\n",
       "     query_scores  \n",
       "133       0.00403  \n",
       "175       0.00766  \n",
       "127       0.00741  \n",
       "6         0.03613  \n",
       "214       0.11311  \n",
       "..            ...  \n",
       "112       0.00164  \n",
       "17        0.00535  \n",
       "13        0.00341  \n",
       "122       0.12221  \n",
       "35        1.00000  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ID</th>\n",
       "      <th>BMU_x</th>\n",
       "      <th>BMU_y</th>\n",
       "      <th>query_scores</th>\n",
       "      <th>SOM_rank</th>\n",
       "      <th>QS_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>v04582_s00192(f017354-f017429)_g00297_f017400.jpg</td>\n",
       "      <td>12773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00403</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>v06055_s00202(f036886-f037073)_g00290_f037072.jpg</td>\n",
       "      <td>16897</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>v06692_s00061(f009716-f009776)_g00088_f009758.jpg</td>\n",
       "      <td>18661</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00741</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v00382_s00002(f003291-f006109)_g00050_f005544.jpg</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03613</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>v05326_s00001(f001841-f013458)_g00225_f008121.jpg</td>\n",
       "      <td>14890</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11311</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>v04803_s00535(f028723-f028786)_g00639_f028771.jpg</td>\n",
       "      <td>13417</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>96</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>v01419_s00073(f003647-f003677)_g00102_f003675.jpg</td>\n",
       "      <td>3885</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>97</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>v01037_s00006(f001673-f001732)_g00011_f001708.jpg</td>\n",
       "      <td>2800</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00341</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>v05033_s00074(f004550-f004599)_g00091_f004575.jpg</td>\n",
       "      <td>14099</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.12221</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>v02098_s00013(f002609-f003250)_g00087_f003116.jpg</td>\n",
       "      <td>5697</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename     ID BMU_x BMU_y  \\\n",
       "133  v04582_s00192(f017354-f017429)_g00297_f017400.jpg  12773     0     0   \n",
       "175  v06055_s00202(f036886-f037073)_g00290_f037072.jpg  16897     0     1   \n",
       "127  v06692_s00061(f009716-f009776)_g00088_f009758.jpg  18661     0     2   \n",
       "6    v00382_s00002(f003291-f006109)_g00050_f005544.jpg   1096     0     3   \n",
       "214  v05326_s00001(f001841-f013458)_g00225_f008121.jpg  14890     0     4   \n",
       "..                                                 ...    ...   ...   ...   \n",
       "112  v04803_s00535(f028723-f028786)_g00639_f028771.jpg  13417     9     5   \n",
       "17   v01419_s00073(f003647-f003677)_g00102_f003675.jpg   3885     9     6   \n",
       "13   v01037_s00006(f001673-f001732)_g00011_f001708.jpg   2800     9     7   \n",
       "122  v05033_s00074(f004550-f004599)_g00091_f004575.jpg  14099     9     8   \n",
       "35   v02098_s00013(f002609-f003250)_g00087_f003116.jpg   5697     9     9   \n",
       "\n",
       "     query_scores  SOM_rank  QS_rank  \n",
       "133       0.00403         1       68  \n",
       "175       0.00766         2       49  \n",
       "127       0.00741         3       51  \n",
       "6         0.03613         4       27  \n",
       "214       0.11311         5       12  \n",
       "..            ...       ...      ...  \n",
       "112       0.00164        96       83  \n",
       "17        0.00535        97       58  \n",
       "13        0.00341        98       76  \n",
       "122       0.12221        99       10  \n",
       "35        1.00000       100        1  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.6463747024536133 seconds\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(frame_ids[0], columns=['ID'])\n",
    "b = pd.DataFrame(query_scores[0], columns=['query_scores'])\n",
    "ab = pd.concat([a, b], axis=1, join='inner')\n",
    "\n",
    "som.display_results(ab, frame_features, ranking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e2630d-0407-458a-9ee7-b4393c77f031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following images were selected by Hungarian Algo: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BMU_x</th>\n",
       "      <th>BMU_y</th>\n",
       "      <th>query_scores</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08505</td>\n",
       "      <td>v06594_s00035(f004610-f004975)_g00071_f004900.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07843</td>\n",
       "      <td>v05509_s00052(f005042-f005141)_g00114_f005100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32380</td>\n",
       "      <td>v00000_s00017(f002103-f002959)_g00050_f002800.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.14411</td>\n",
       "      <td>v02879_s00046(f005836-f006173)_g00127_f005994.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18843</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08343</td>\n",
       "      <td>v06769_s00069(f009408-f009738)_g00130_f009422.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5645</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86154</td>\n",
       "      <td>v02083_s00068(f006057-f006208)_g00171_f006083.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10496</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.07137</td>\n",
       "      <td>v03798_s00030(f004646-f004785)_g00086_f004680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>14911</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.07515</td>\n",
       "      <td>v05332_s00051(f004908-f005001)_g00130_f004975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>19706</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06889</td>\n",
       "      <td>v07055_s00085(f006951-f006993)_g00209_f006975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2810</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.12257</td>\n",
       "      <td>v01039_s00120(f009678-f009765)_g00223_f009680.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID BMU_x BMU_y  query_scores  \\\n",
       "0   18358     0     0       0.08505   \n",
       "1   15387     0     1       0.07843   \n",
       "2       1     0     2       0.32380   \n",
       "3    7890     0     3       0.14411   \n",
       "4   18843     0     4       0.08343   \n",
       "..    ...   ...   ...           ...   \n",
       "95   5645     9     5       0.86154   \n",
       "96  10496     9     6       0.07137   \n",
       "97  14911     9     7       0.07515   \n",
       "98  19706     9     8       0.06889   \n",
       "99   2810     9     9       0.12257   \n",
       "\n",
       "                                             filename  \n",
       "0   v06594_s00035(f004610-f004975)_g00071_f004900.jpg  \n",
       "1   v05509_s00052(f005042-f005141)_g00114_f005100.jpg  \n",
       "2   v00000_s00017(f002103-f002959)_g00050_f002800.jpg  \n",
       "3   v02879_s00046(f005836-f006173)_g00127_f005994.jpg  \n",
       "4   v06769_s00069(f009408-f009738)_g00130_f009422.jpg  \n",
       "..                                                ...  \n",
       "95  v02083_s00068(f006057-f006208)_g00171_f006083.jpg  \n",
       "96  v03798_s00030(f004646-f004785)_g00086_f004680.jpg  \n",
       "97  v05332_s00051(f004908-f005001)_g00130_f004975.jpg  \n",
       "98  v07055_s00085(f006951-f006993)_g00209_f006975.jpg  \n",
       "99  v01039_s00120(f009678-f009765)_g00223_f009680.jpg  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>BMU_x</th>\n",
       "      <th>BMU_y</th>\n",
       "      <th>query_scores</th>\n",
       "      <th>filename</th>\n",
       "      <th>SOM_rank</th>\n",
       "      <th>QS_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08505</td>\n",
       "      <td>v06594_s00035(f004610-f004975)_g00071_f004900.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07843</td>\n",
       "      <td>v05509_s00052(f005042-f005141)_g00114_f005100.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32380</td>\n",
       "      <td>v00000_s00017(f002103-f002959)_g00050_f002800.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.14411</td>\n",
       "      <td>v02879_s00046(f005836-f006173)_g00127_f005994.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18843</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.08343</td>\n",
       "      <td>v06769_s00069(f009408-f009738)_g00130_f009422.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5645</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86154</td>\n",
       "      <td>v02083_s00068(f006057-f006208)_g00171_f006083.jpg</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10496</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.07137</td>\n",
       "      <td>v03798_s00030(f004646-f004785)_g00086_f004680.jpg</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>14911</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.07515</td>\n",
       "      <td>v05332_s00051(f004908-f005001)_g00130_f004975.jpg</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>19706</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06889</td>\n",
       "      <td>v07055_s00085(f006951-f006993)_g00209_f006975.jpg</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2810</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.12257</td>\n",
       "      <td>v01039_s00120(f009678-f009765)_g00223_f009680.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID BMU_x BMU_y  query_scores  \\\n",
       "0   18358     0     0       0.08505   \n",
       "1   15387     0     1       0.07843   \n",
       "2       1     0     2       0.32380   \n",
       "3    7890     0     3       0.14411   \n",
       "4   18843     0     4       0.08343   \n",
       "..    ...   ...   ...           ...   \n",
       "95   5645     9     5       0.86154   \n",
       "96  10496     9     6       0.07137   \n",
       "97  14911     9     7       0.07515   \n",
       "98  19706     9     8       0.06889   \n",
       "99   2810     9     9       0.12257   \n",
       "\n",
       "                                             filename  SOM_rank  QS_rank  \n",
       "0   v06594_s00035(f004610-f004975)_g00071_f004900.jpg         1       75  \n",
       "1   v05509_s00052(f005042-f005141)_g00114_f005100.jpg         2       86  \n",
       "2   v00000_s00017(f002103-f002959)_g00050_f002800.jpg         3       12  \n",
       "3   v02879_s00046(f005836-f006173)_g00127_f005994.jpg         4       36  \n",
       "4   v06769_s00069(f009408-f009738)_g00130_f009422.jpg         5       77  \n",
       "..                                                ...       ...      ...  \n",
       "95  v02083_s00068(f006057-f006208)_g00171_f006083.jpg        96        2  \n",
       "96  v03798_s00030(f004646-f004785)_g00086_f004680.jpg        97       93  \n",
       "97  v05332_s00051(f004908-f005001)_g00130_f004975.jpg        98       88  \n",
       "98  v07055_s00085(f006951-f006993)_g00209_f006975.jpg        99       98  \n",
       "99  v01039_s00120(f009678-f009765)_g00223_f009680.jpg       100       46  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.6214120388031006 seconds\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(frame_ids[0], columns=['ID'])\n",
    "b = pd.DataFrame(query_scores[0], columns=['query_scores'])\n",
    "ab = pd.concat([a, b], axis=1, join='inner')\n",
    "\n",
    "biased_som.display_results(ab, frame_features, ranking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbbf9e2-c1ea-47da-bea5-0461a2be4783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_distance_matrix: \n",
      "\n",
      "[[1.25411 1.51603 1.59204 1.57529 1.4399  1.46328 1.40872 1.5081  1.5813\n",
      "  1.83708]\n",
      " [1.71943 1.56478 1.49685 1.49022 1.31228 1.26349 1.33087 1.38015 1.51089\n",
      "  1.61019]\n",
      " [1.59889 1.52032 1.54495 1.43873 1.43249 1.48649 1.45806 1.44036 1.51219\n",
      "  1.57885]\n",
      " [1.51867 1.36196 1.48011 1.4127  1.49898 1.50736 1.49316 1.52758 1.49903\n",
      "  1.56421]\n",
      " [1.51423 1.36297 1.38529 1.47154 1.36847 1.48676 1.46426 1.40652 1.33559\n",
      "  1.44217]\n",
      " [1.52583 1.45276 1.46872 1.48414 1.40044 1.26696 1.43554 1.27568 1.29346\n",
      "  1.3214 ]\n",
      " [1.45115 1.36572 1.46057 1.48676 1.49242 1.35367 1.45495 1.46826 1.31631\n",
      "  1.35719]\n",
      " [1.44806 1.33838 1.45071 1.49361 1.47978 1.48261 1.51834 1.46574 1.39343\n",
      "  1.52572]\n",
      " [1.44531 1.324   1.39476 1.45609 1.41813 1.44363 1.51219 1.46246 1.40769\n",
      "  1.35147]\n",
      " [1.56616 1.45702 1.47454 1.42189 1.53009 1.45245 1.41784 1.60718 1.54301\n",
      "  1.64422]]\n",
      "\n",
      "mean_distance_nextdoor: \n",
      "\n",
      "[[1.13104 0.56552 0.54763 0.65171 0.63781 0.60955 0.49061 0.55966 0.66851\n",
      "  1.23814]\n",
      " [1.39279 0.69639 0.65508 0.61115 0.69798 0.23458 0.52508 0.59286 0.70543\n",
      "  1.26766]\n",
      " [1.23649 0.61825 0.70425 0.65671 0.65706 0.64237 0.68725 0.47341 0.68112\n",
      "  1.2153 ]\n",
      " [1.04129 0.52065 0.62361 0.64342 0.61005 0.6826  0.65875 0.69964 0.62327\n",
      "  1.29026]\n",
      " [1.21356 0.60678 0.59712 0.58568 0.6518  0.64032 0.54945 0.60154 0.63271\n",
      "  0.97458]\n",
      " [1.36066 0.68033 0.67794 0.67746 0.70486 0.46023 0.55658 0.59381 0.44086\n",
      "  1.21329]\n",
      " [1.13322 0.56661 0.54313 0.72753 0.67911 0.5712  0.58134 0.68428 0.65162\n",
      "  1.03696]\n",
      " [1.12785 0.56392 0.61066 0.61652 0.64766 0.57545 0.68155 0.55033 0.54896\n",
      "  1.33265]\n",
      " [1.24315 0.62157 0.55178 0.63763 0.6338  0.55344 0.63781 0.65521 0.64327\n",
      "  0.88048]\n",
      " [1.16747 0.58373 0.65586 0.51221 0.59276 0.56481 0.42404 0.63286 0.64535\n",
      "  1.26198]]\n"
     ]
    }
   ],
   "source": [
    "som.mean_distance(print_result=True)\n",
    "som.mean_distance_nextdoor(print_result=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abaf95c8-4267-4a05-b791-bfa71ed0c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_distance_matrix: \n",
      "\n",
      "[[1.20631 1.37352 1.2954  1.37234 1.22617 1.19929 1.25654 1.48416 1.38169\n",
      "  1.64566]\n",
      " [1.59856 1.36694 1.31694 1.22291 1.29886 1.3864  1.39363 1.34347 1.40818\n",
      "  1.39549]\n",
      " [1.35235 1.21258 1.24537 1.31245 1.50098 1.45908 1.44231 1.43467 1.41108\n",
      "  1.40433]\n",
      " [1.53928 1.19255 1.1573  1.35115 1.3888  1.22893 1.31725 1.37544 1.36832\n",
      "  1.38998]\n",
      " [1.3904  1.11283 1.12999 1.14914 1.10958 1.20335 1.09986 1.35535 1.41376\n",
      "  1.38276]\n",
      " [1.54878 1.14855 1.00473 1.06065 1.29144 1.17501 1.111   1.3226  1.36972\n",
      "  1.37115]\n",
      " [1.32166 1.40046 1.10218 1.32531 1.37698 1.11277 1.01744 1.08058 1.2923\n",
      "  1.31785]\n",
      " [1.44387 1.20183 1.11512 1.05026 1.08059 1.19754 0.88507 1.02738 1.1842\n",
      "  1.20527]\n",
      " [1.43203 1.40417 0.99513 1.01917 0.88601 0.88984 0.91518 0.88559 0.91614\n",
      "  1.28316]\n",
      " [1.51822 1.19699 1.02719 0.96628 0.89964 0.83237 1.05821 0.98629 0.98809\n",
      "  1.25126]]\n",
      "\n",
      "mean_distance_nextdoor: \n",
      "\n",
      "[[1.24659 0.6233  0.40482 0.43145 0.63696 0.33638 0.3225  0.56605 0.65805\n",
      "  1.05373]\n",
      " [1.30459 0.6523  0.59265 0.44885 0.64808 0.46957 0.67931 0.59223 0.56746\n",
      "  1.26842]\n",
      " [0.73825 0.36912 0.56214 0.46639 0.67723 0.59172 0.66955 0.69995 0.59965\n",
      "  1.08995]\n",
      " [1.32403 0.66201 0.54524 0.51284 0.34711 0.56489 0.53661 0.51609 0.55429\n",
      "  1.17493]\n",
      " [0.90355 0.45177 0.50142 0.41409 0.38633 0.45374 0.49979 0.59993 0.518\n",
      "  1.29525]\n",
      " [1.31636 0.65818 0.39381 0.35059 0.61477 0.5913  0.31213 0.54045 0.56741\n",
      "  1.25502]\n",
      " [1.31631 0.65816 0.6225  0.61315 0.58439 0.58599 0.32005 0.22419 0.59332\n",
      "  1.20688]\n",
      " [1.02305 0.51152 0.46435 0.39147 0.3282  0.55828 0.46352 0.40574 0.42359\n",
      "  1.07109]\n",
      " [1.26022 0.63011 0.62014 0.46472 0.45107 0.30755 0.29234 0.30606 0.36881\n",
      "  1.094  ]\n",
      " [1.07087 0.53544 0.22327 0.36478 0.35864 0.29798 0.44085 0.52235 0.32356\n",
      "  0.85056]]\n"
     ]
    }
   ],
   "source": [
    "biased_som.mean_distance(print_result=True)\n",
    "biased_som.mean_distance_nextdoor(print_result=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72519834-8660-40df-8c77-48c682c70c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02343434343434344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som.tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56c33c3-fce0-4c41-b729-b53dedec892a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7486023513020942"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som.nDCG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5a8d70-7fb7-45de-a79e-9826f062fe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som._input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0225b257-23c6-4f82-b1c4-9f1daf16a203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034747474747474756"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_som.tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb2c957e-edaa-4430-86b1-31455e0b9679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6800081016184968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_som.nDCG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b30a9-b736-4fa7-ba17-b43acfb6d3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
